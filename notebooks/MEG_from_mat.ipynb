{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "2268\n",
      "/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MRIDATA\n",
      "Starting filtering\n",
      "Opening raw data file /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc.fif...\n",
      "    Range : 22000 ... 895999 =     22.000 ...   895.999 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:19: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw(raw_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 873999  =      0.000 ...   873.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc_filtered.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    5.4s finished\n",
      "/home/guibert/MEG_analysis/src/data/preprocess.py:23: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc_filtered.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_filt.save(get_filtered_fname(raw_path), overwrite=overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc_filtered.fif\n",
      "[done]\n",
      "Done and saved.\n",
      "Starting ICA\n",
      "Opening raw data file /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc_filtered.fif...\n",
      "    Range : 22000 ... 895999 =     22.000 ...   895.999 secs\n",
      "Ready.\n",
      "Reading 0 ... 873999  =      0.000 ...   873.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:29: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc_filtered.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw(get_filtered_fname(raw_path), preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 306 channels (please be patient, this may take a while)\n",
      "Selecting by explained variance: 69 components\n",
      "Fitting ICA took 235.1s.\n",
      "Creating RawArray with float64 data, n_channels=72, n_times=874000\n",
      "    Range : 22000 ... 895999 =     22.000 ...   895.999 secs\n",
      "Ready.\n",
      "Using qt as 2D backend.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (69 components)\n",
      "    Zeroing out 2 ICA components\n",
      "    Projecting back using 306 PCA components\n",
      "Overwriting existing file.\n",
      "Writing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc_filtered_icaed.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:36: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc_filtered_icaed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(get_icaed_fname(raw_path), overwrite=overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc_filtered_icaed.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing ICA solution to /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc_ica-model.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:37: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2268/nBack_tsss_mc_ica-model.fif) does not conform to MNE naming conventions. All ICA files should end with -ica.fif, -ica.fif.gz, _ica.fif or _ica.fif.gz\n",
      "  ica.save(get_ica_model_fname(raw_path), overwrite=overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and saved.\n",
      "Done with computations.\n",
      "2278\n",
      "/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MRIDATA\n",
      "Starting filtering\n",
      "Opening raw data file /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc.fif...\n",
      "    Range : 19000 ... 897999 =     19.000 ...   897.999 secs\n",
      "Ready.\n",
      "Reading 0 ... 878999  =      0.000 ...   878.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:19: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw(raw_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc_filtered.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    5.8s finished\n",
      "/home/guibert/MEG_analysis/src/data/preprocess.py:23: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc_filtered.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_filt.save(get_filtered_fname(raw_path), overwrite=overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc_filtered.fif\n",
      "[done]\n",
      "Done and saved.\n",
      "Starting ICA\n",
      "Opening raw data file /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc_filtered.fif...\n",
      "    Range : 19000 ... 897999 =     19.000 ...   897.999 secs\n",
      "Ready.\n",
      "Reading 0 ... 878999  =      0.000 ...   878.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:29: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc_filtered.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw(get_filtered_fname(raw_path), preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 306 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by explained variance: 72 components\n",
      "Fitting ICA took 262.5s.\n",
      "Creating RawArray with float64 data, n_channels=75, n_times=879000\n",
      "    Range : 19000 ... 897999 =     19.000 ...   897.999 secs\n",
      "Ready.\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "Not setting metadata\n",
      "439 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (72 components)\n",
      "    Zeroing out 6 ICA components\n",
      "    Projecting back using 306 PCA components\n",
      "Overwriting existing file.\n",
      "Writing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc_filtered_icaed.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:36: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc_filtered_icaed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(get_icaed_fname(raw_path), overwrite=overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc_filtered_icaed.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing ICA solution to /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc_ica-model.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:37: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2278/nBack_tsss_mc_ica-model.fif) does not conform to MNE naming conventions. All ICA files should end with -ica.fif, -ica.fif.gz, _ica.fif or _ica.fif.gz\n",
      "  ica.save(get_ica_model_fname(raw_path), overwrite=overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and saved.\n",
      "Done with computations.\n",
      "2279\n",
      "/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MRIDATA\n",
      "Starting filtering\n",
      "Opening raw data file /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc.fif...\n",
      "    Range : 27000 ... 898999 =     27.000 ...   898.999 secs\n",
      "Ready.\n",
      "Reading 0 ... 871999  =      0.000 ...   871.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:19: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw(raw_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc_filtered.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    5.4s finished\n",
      "/home/guibert/MEG_analysis/src/data/preprocess.py:23: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc_filtered.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_filt.save(get_filtered_fname(raw_path), overwrite=overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc_filtered.fif\n",
      "[done]\n",
      "Done and saved.\n",
      "Starting ICA\n",
      "Opening raw data file /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc_filtered.fif...\n",
      "    Range : 27000 ... 898999 =     27.000 ...   898.999 secs\n",
      "Ready.\n",
      "Reading 0 ... 871999  =      0.000 ...   871.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:29: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc_filtered.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw(get_filtered_fname(raw_path), preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 306 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by explained variance: 70 components\n",
      "Fitting ICA took 296.0s.\n",
      "Creating RawArray with float64 data, n_channels=73, n_times=872000\n",
      "    Range : 27000 ... 898999 =     27.000 ...   898.999 secs\n",
      "Ready.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (70 components)\n",
      "    Zeroing out 3 ICA components\n",
      "    Projecting back using 306 PCA components\n",
      "Overwriting existing file.\n",
      "Writing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc_filtered_icaed.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:36: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc_filtered_icaed.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw.save(get_icaed_fname(raw_path), overwrite=overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc_filtered_icaed.fif\n",
      "[done]\n",
      "Overwriting existing file.\n",
      "Writing ICA solution to /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc_ica-model.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:37: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2279/nBack_tsss_mc_ica-model.fif) does not conform to MNE naming conventions. All ICA files should end with -ica.fif, -ica.fif.gz, _ica.fif or _ica.fif.gz\n",
      "  ica.save(get_ica_model_fname(raw_path), overwrite=overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and saved.\n",
      "Done with computations.\n",
      "2304\n",
      "/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MRIDATA\n",
      "Starting filtering\n",
      "Opening raw data file /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2304/nBack_tsss_mc.fif...\n",
      "    Range : 12000 ... 882999 =     12.000 ...   882.999 secs\n",
      "Ready.\n",
      "Reading 0 ... 870999  =      0.000 ...   870.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:19: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2304/nBack_tsss_mc.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw(raw_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2304/nBack_tsss_mc_filtered.fif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    5.4s finished\n",
      "/home/guibert/MEG_analysis/src/data/preprocess.py:23: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2304/nBack_tsss_mc_filtered.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw_filt.save(get_filtered_fname(raw_path), overwrite=overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2304/nBack_tsss_mc_filtered.fif\n",
      "[done]\n",
      "Done and saved.\n",
      "Starting ICA\n",
      "Opening raw data file /media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2304/nBack_tsss_mc_filtered.fif...\n",
      "    Range : 12000 ... 882999 =     12.000 ...   882.999 secs\n",
      "Ready.\n",
      "Reading 0 ... 870999  =      0.000 ...   870.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guibert/MEG_analysis/src/data/preprocess.py:29: RuntimeWarning: This filename (/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/2304/nBack_tsss_mc_filtered.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw(get_filtered_fname(raw_path), preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 306 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 306 out of 306 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by explained variance: 71 components\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path as Path\n",
    "sys.path.append(os.path.abspath(Path(\"..\")))\n",
    "from scipy.io import loadmat\n",
    "from src.data.preprocess import preprocess_fif\n",
    "\n",
    "atlas_orig_path = \"/home/guibert/parcellations/fmri_d100_parcellation_with_PCC_tighterMay15_v2_2mm.nii.gz\"\n",
    "atlas_thresholded = \"/home/guibert/parcellations/fmri_d100_parcellation_with_PCC_tighterMay15_v2_2mm_thresholded.nii.gz\"\n",
    "atlas_t1_ref = Path(os.environ[\"FSL_DIR\"],\"data/standard/MNI152_T1_2mm_brain.nii.gz\")\n",
    "\n",
    "# Prepare the atlas by thresholding regions and making it a 3D volume.\n",
    "# Original atlas contains 42 principal components.\n",
    "#threshold_4D_atlas_and_save_based_on_ref(atlas_orig_path,atlas_t1_ref, atlas_thresholded, 2)\n",
    "\n",
    "subjects_mri_dir = \"/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MRIDATA\"\n",
    "subjects_fif_dir = '/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/'\n",
    "\n",
    "healthy_subjects_codes = loadmat(\"/media/miplab-nas2/Data/guibert/nBack_complete/nBack_Share_HC/subjects_code_HC.mat\")['HC']\n",
    "subjects_interest = [ e for e in healthy_subjects_codes]\n",
    "\n",
    "skip_steps = [\"coreg\", \"bem_mesh\", \"source setup\", \"fwd\", \"source rec\", \"source ortho\", \"atlasing\"]\n",
    "# Preprocessing steps\n",
    "subjects_filtered = [s for s in subjects_interest if os.path.exists(os.path.join(subjects_fif_dir, str(s)))]\n",
    "\n",
    "for s in subjects_filtered[18:]:\n",
    "    preprocess_fif(str(s), subjects_fif_dir, subjects_mri_dir, atlas_t1_ref, atlas_thresholded, skip_steps=skip_steps, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed7ecfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2278',\n",
       " '2279',\n",
       " '2304',\n",
       " '2312',\n",
       " '2314',\n",
       " '2318',\n",
       " '2319',\n",
       " '2325',\n",
       " '2327',\n",
       " '2328',\n",
       " '2341',\n",
       " '2342',\n",
       " '2359',\n",
       " '2410',\n",
       " '2414',\n",
       " '2427',\n",
       " '2448']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_filtered[19:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbaa3b6",
   "metadata": {},
   "source": [
    "## Sign disambiguation\n",
    "\n",
    "One step proposed by Vidaurre et al is a sign disambiguation, to ensure partial correlation matrices are consistent across participants. Let's apply this step. Vidaurre, in his original algorithm, proposed to conduct time-embedding before the sign disambiguation, to compute lagged partial correlation matrices directly. Let's indeed do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290af590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.models.sign_flip import compute_flips_participants_and_apply\n",
    "# Now we can get the subjects and compute their partial correlations!\n",
    "compute_flips_participants_and_apply(subjects_fif_dir, subjects_filtered, 100, 200, 7, cov_mode=\"empirical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71119d7d",
   "metadata": {},
   "source": [
    "## Transformation: temporal embedding and PCA\n",
    "Data is transformed with a temporal embedding and fed to an incremental PCA based on entire population.\n",
    "How many components to keep ? According to the article, this was twice the number of ROIs. Let's do that exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ade40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.temporal_embedding import time_embedding_step, group_embedding_and_pca\n",
    "\n",
    "for s in subjects_filtered:\n",
    "    print(\"Starting time embedding of {}\".format(s))\n",
    "    time_embedding_step(subjects_fif_dir, s, L=7, is_flipped=True)\n",
    "    print(\"Done for {}\".format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3663c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.temporal_embedding import group_embedding_and_pca\n",
    "group_embedding_and_pca(subjects_filtered, subjects_fif_dir, whiten=True, L=7, is_flipped=True, n_components=39*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b3e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.fname_conventions import get_subject_raw_path\n",
    "from src.data.preprocess import annotate_from_ica_downsample_and_save\n",
    "for s in subjects_filtered:\n",
    "    annotate_from_ica_downsample_and_save(get_subject_raw_path(subjects_fif_dir, s), 250, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b6fde0",
   "metadata": {},
   "source": [
    "## HMM analysis\n",
    "We're finally ready to start analysis of the entire dataset.\n",
    "Aiming to reproduce the HMM, we apply first K-Means instead of the spectral method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb040f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.hmm_models import fit_and_predict_proba_subjects\n",
    "from src.data.fname_conventions import get_pca_transformed_time_embedding\n",
    "import numpy as np\n",
    "\n",
    "hmm_data, predicted_probas, lengths = fit_and_predict_proba_subjects(subjects_fif_dir, subjects_filtered, n_states=6, n_components=39*2, is_flipped=True, L=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save probabilities and lengthes to ensure\n",
    "from pathlib import Path as Path\n",
    "\n",
    "np.save(Path(subjects_fif_dir, \"state_probabilities_filt.npy\"), predicted_probas)\n",
    "np.save(Path(subjects_fif_dir, \"sessions_lengths_filt.npy\"), np.array(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88adfcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicted_probas = np.load(Path(subjects_fif_dir, \"state_probabilities_filt.npy\"))\n",
    "lengths = np.load(Path(subjects_fif_dir, \"sessions_lengths_filt.npy\"))\n",
    "\n",
    "lengths\n",
    "\n",
    "cum_lengths = np.concatenate(([0], np.cumsum(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Visualize timecourses PRIOR to source rec to see how events are distributed with final annotations\n",
    "# How many samples?\n",
    "# Compare with atlased source rec: how many samples?\n",
    "import mne\n",
    "import numpy as np\n",
    "from src.data.fname_conventions import get_icaed_annotated_fname, get_subject_raw_path\n",
    "from src.data.event_extractor import get_events_from_annotated_raw\n",
    "from pathlib import Path as Path\n",
    "\n",
    "n_samples = []\n",
    "for i, s in enumerate(subjects_filtered):\n",
    "    data_subject = mne.io.read_raw(get_icaed_annotated_fname(get_subject_raw_path(subjects_fif_dir, s)))\n",
    "    n_samples.append(data_subject.n_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.epochs_glm import run_two_level_glm\n",
    "conditions = ['0-back D', '0-back T', '1-back D', '1-back T', '2-back D', '2-back T']\n",
    "first_level_res, second_level_res = run_two_level_glm(subjects_filtered, subjects_fif_dir, predicted_probas, cum_lengths, conditions, -0.2, 1.2, (-0.2, -0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_axisbelow(True)\n",
    "ax.xaxis.grid(color='gray', linestyle='dashed')\n",
    "for i in range(6):\n",
    "    plt.plot(np.linspace(-0.2,1.2, 351), second_level_res[i,:,0], label=\"State {}\".format(i))\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"State probability (A.U.)\")\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485ac9d",
   "metadata": {},
   "source": [
    "### Obtaining the spatial distribution\n",
    "\n",
    "To get spatial distribution of each state given its timecourse, we can apply the steps of Baum-Welch. Based on state sequence and data, estimate mean of a state based on original data (not PCA-temporal data anymore)! We thus don't have the issue of the PCA transform having to be mapped back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.fname_conventions import get_sign_corrected_fname\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "population_psd_estimates = []\n",
    "# Load back subjects\n",
    "for i, s in enumerate(subjects_filtered):\n",
    "    x = np.load(get_sign_corrected_fname(subjects_fif_dir, s))\n",
    "    \n",
    "    subj_psd_estimates = []\n",
    "    \n",
    "    # Get timecourses corresponding to current participant\n",
    "    # From the states, get the timecourses\n",
    "    subject_states_tc = predicted_probas[cum_lengths[i]:cum_lengths[i+1],:]\n",
    "    n_states = subject_states_tc.shape[1]\n",
    "    for state_i in range(n_states):\n",
    "        state_weighted_res = x * subject_states_tc[:,i]\n",
    "        # Compute PSD\n",
    "        \n",
    "        psds, freqs = psd_array_multitaper(state_weighted_res, sfreq=250, fmin=1, fmax=40)\n",
    "        \n",
    "        # Append result\n",
    "        subj_psd_estimates.append([psds,freqs])\n",
    "    # Append to global\n",
    "    population_psd_estimates.append(subj_psd_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b2fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_psd_estimates[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a6afe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ddb525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e64d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583884ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d60d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33600c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.fname_conventions import get_events_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca674a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.asarray(n_samples) == lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed33688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work on first subject to understand better.\n",
    "# Here is what one WOULD like:\n",
    "# -> Annotation times and event times are well matched\n",
    "# -> Could we add these to our newly formed session properly?\n",
    "s = subjects_filtered[10]\n",
    "data_subject = mne.io.read_raw(get_icaed_annotated_fname(get_subject_raw_path(subjects_fif_dir, s)))\n",
    "\n",
    "events, events_dict = get_events_from_annotated_raw(data_subject)\n",
    "event_table = np.loadtxt(get_events_fname(get_subject_raw_path(subjects_fif_dir, s)), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66494d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.models.hmm_models import create_raw_states_data\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from src.models.epochs_glm import create_design_mat_and_run_glm\n",
    "import mne\n",
    "\n",
    "\n",
    "cum_lengths = np.concatenate([[0], np.cumsum(np.array(lengths))])\n",
    "conditions = ['0-back D', '0-back T', '1-back D', '1-back T', '2-back D', '2-back T']\n",
    "\n",
    "design_mats = []\n",
    "labels_pop = []\n",
    "results_pop = []\n",
    "events_pop = []\n",
    "# For each subject, run a GLM and save the coeffs\n",
    "for i, s in enumerate(subjects_filtered):\n",
    "    data_subject = mne.io.read_raw(get_icaed_annotated_fname(get_subject_raw_path(subjects_fif_dir, s)))\n",
    "    events, events_dict = get_events_from_annotated_raw(data_subject)\n",
    "    \n",
    "    raw_i = create_raw_states_data(predicted_probas[cum_lengths[i]:cum_lengths[i+1],:], data_subject)\n",
    "    \n",
    "    # Create the design matrix: use the events!\n",
    "    # Run first level GLM:\n",
    "    # Create design matrix from conditions and events, concatenate epochs and run the GLM\n",
    "    # Run the GLM!\n",
    "    design_mat, labels, results = create_design_mat_and_run_glm(raw_i, events, events_dict, tmin=-0.2, \n",
    "                                                                tmax=1.2, \n",
    "                                                                baseline=(-0.2,-0.03), conditions=conditions)\n",
    "    design_mats.append(design_mat)\n",
    "    labels_pop.append(labels)\n",
    "    results_pop.append(results)\n",
    "    events_pop.append(events)\n",
    "    plot_design_matrix(design_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then! \n",
    "# -> Create contrasts\n",
    "# -> Apply GLM at second level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next:\n",
    "# -> Multitaper here: https://mne.tools/stable/generated/mne.time_frequency.psd_array_multitaper.html#mne.time_frequency.psd_array_multitaper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea16d243",
   "metadata": {},
   "source": [
    "### TF analysis: oscillatory analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc9313",
   "metadata": {},
   "outputs": [],
   "source": [
    "stc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494779ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_space = mne.read_source_spaces(os.path.join(\"/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MRIDATA/1006\",\"1006-src-vol.stc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path.replace(\"nBack_tsss_mc.fif\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86655b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stc_2 = stc.copy().crop(tmin=0, tmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stc_2.save_as_volume(fname=\"/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/1006/vols.nii.gz\", src=src_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b729b6",
   "metadata": {},
   "source": [
    "### Multiscale analysis\n",
    "\n",
    "Following the PCA decomposition, we perform a wavelet transformation of the signal at multiple scales. The wavelet is done along time: we're in effect looking at different timescales this way.\n",
    "\n",
    "One HMM is fit for each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb1bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a wavelet decomposition of the signal\n",
    "wavelet_decomps = decompose_as_multi_level(pca_data, 'db5')\n",
    "\n",
    "# How many states are descriptive at each level? Let's plot to decide!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "annots = get_annotations_from_raw(raw_path, mne.io.read_raw(raw_path.replace('.fif', '_filtered_icaed.fif'), preload=False), \"STI101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17754f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53210082",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_decomps[13].shape[1] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90dcee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = 11\n",
    "p = len(wavelet_decomps) - i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "#i = 13\n",
    "#p = len(wavelet_decomps) - i\n",
    "hmms = estimate_hmm_multiscale([wavelet_decomps[i]], [k])\n",
    "pred_probas = hmms[0].predict_proba(wavelet_decomps[i].T)\n",
    "#raw_path = os.path.join(subjects_fif_dir, subject_name, \"nBack_tsss_mc.fif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ts_reconstructed = convert_state_preds_to_raw(\"hmm-wavelet-source_space\", 389, pca_data, annots, 250)\n",
    "raw_ts_reconstructed.save(raw_path.replace('.fif', '_pca-source_space.fif'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cfd4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ts_reconstructed = convert_state_preds_to_raw(\"hmm-wavelet-source_space\", k, pred_probas, annots, 250 / 2**p)\n",
    "raw_ts_reconstructed.save(raw_path.replace('.fif', '_hmm-source_space.fif'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29507aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To downsample: we take every K sample (easy enough, right?)\n",
    "# Let's downsample by a factor of 16\n",
    "pca_data_low = pca_data[:, ::16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_model = hmm.GaussianHMM(n_components=10)\n",
    "hmm_model.fit(pca_data_low.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2ded8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_states = hmm_model.predict(pca_data_low.T).reshape((-1, 1))\n",
    "raw_ts_reconstructed = convert_state_preds_to_raw(\"hmm-states_source_space\", 1, pred_states.T, annots, 250 / 16)\n",
    "raw_ts_reconstructed.save(raw_path.replace('.fif', '_hmm-states_source_space.fif'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ts_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_low = hmm_model.predict_proba(pca_data_low.T)\n",
    "raw_ts_reconstructed = convert_state_preds_to_raw(\"hmm-source_space\", 10, preds_low.T, annots, 250 / 16)\n",
    "raw_ts_reconstructed.save(raw_path.replace('.fif', '_hmm-source_space.fif'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "events, event_ids = mne.events_from_annotations(raw_ts_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the above events, we're able to define for starters three categories: the \"0-back\", \"1-back\" and \"2-back\"\n",
    "# trials, when participant was correct.\n",
    "# For these trials ONLY, let's take the wavelet transforms and ask which resolution is sufficient to classify.\n",
    "\n",
    "\n",
    "# For each resolution:\n",
    "#      Create the epoched data\n",
    "#      Train an SVM between categories. Each epoch results in a set of features 1st channel of coefficients\n",
    "#      Also train a 1-NN classifier\n",
    "# Deduce\n",
    "\n",
    "plt.plot(wavelet_decomps[10][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d233c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the above plots, starting at i = 11, here are the states:\n",
    "k_spectral = [3, 3, 9, 10, 15, 12, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830db5b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Free RAM\n",
    "del stc, pca_data, p12\n",
    "# Now fit an HMM for each level\n",
    "hmm_models = estimate_hmm_multiscale(wavelet_decomps[11:], k_spectral)\n",
    "\n",
    "# Perform predictions for each hmm level to get state probabilities\n",
    "preds_ts = []\n",
    "j = 0\n",
    "for i in range(11,len(wavelet_decomps)):\n",
    "    preds_ts.append(hmm_models[j].predict_proba(wavelet_decomps[i].T))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d11a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the HMMs (still in case of crash)\n",
    "hmm_models_path = os.path.join(subjects_fif_dir, subject_name, \"hmm_models.dat\")\n",
    "with open(hmm_models_path, \"wb\") as f:\n",
    "    pickle.dump(hmm_models, f)\n",
    "\n",
    "# Save the data (in case of crash)\n",
    "pick_hmm_predictions_path = os.path.join(subjects_fif_dir, subject_name, \"hmm_preds.dat\")\n",
    "with open(pick_hmm_predictions_path, \"wb\") as f:\n",
    "    pickle.dump(preds_ts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a5b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to see prediction sizes\n",
    "for i in range(len(preds_ts)):\n",
    "    print(preds_ts[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f4bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "freq = 250 * (2**i)\n",
    "\n",
    "raw_ts_reconstructed = convert_state_preds_to_raw(\"hmm-wavelet-scale_{}\".format(len(k_spectral) + i), k_spectral[i], preds_ts[i].T, annots, freq)\n",
    "raw_ts_reconstructed.set_annotations(annots)\n",
    "raw_ts_reconstructed.save(raw_path.replace('.fif', \"hmm-wavelet-scale_{}.fif\".format(len(k_spectral) + i)), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95a5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cec327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to visualize, HERE is what we propose:\n",
    "# The sampling freq is conceptually what has been affected! So: let us plot it now!\n",
    "raw_ts_reconstructed = convert_state_preds_to_raw(\"kmeans-scale_{}\", k_spectral[], preds_ts[i], annots, 250/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the predictions in the same \"time resolution\" as the events to decide on their diagnostic power.\n",
    "for i in range(len(preds_ts)):\n",
    "    preds_ts[i] = repeat_coeffs_with_padding(preds_ts[i], n_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc60096",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605039b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_preds_details = convert_state_preds_to_raw(\"model_low\", k_spectral[0], preds_ts[0], annots)\n",
    "\n",
    "# Save to analyze outside of here\n",
    "state_preds_details.save(raw_path.replace('.fif', '_states_proba.fif'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699ed58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aae13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0a383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12446d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29458d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b670fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can first start by diagnosing the timecourses, in other words: we can do epoching!\n",
    "events, events_id = get_events_from_annotated_raw(state_raw)\n",
    "epochs = mne.Epochs(state_raw, events=events[:-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff25563",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_events_id(events_id):\n",
    "    order = np.array([1, 2, 7, 8, 3, 4, 9, 10, 5, 6, 11, 12])\n",
    "    ids_order = []\n",
    "    for i in order:\n",
    "        if i in events_id:\n",
    "            ids_order.append(events_id.index(i))\n",
    "    return ids_order\n",
    "\n",
    "def sort_averages_by_stim_type(avgs):\n",
    "    order = np.array([1, 2, 7, 8, 3, 4, 9, 10, 5, 6, 11, 12])\n",
    "    ids_order = sort_events_id(avg_comments)\n",
    "    return np.array(avgs)[ids_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by looking at average tendencies, shall we?\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Let's create one epochs array per \n",
    "avgs = sort_averages_by_stim_type(epochs.average(picks=epochs.ch_names,by_event_type=True))\n",
    "figs, axs = plt.subplots(nrows=K, ncols=len(avgs), figsize=(150,150))\n",
    "\n",
    "fontsize=90\n",
    "labelsize=50\n",
    "\n",
    "for i in range(K):\n",
    "    for j in range(len(avgs)):\n",
    "        avg = avgs[j]\n",
    "        axs[i,j].plot(epochs.times, avg.data[i,:]) #, title=rev_annots[int(avg.comment)])\n",
    "        axs[i,j].set_ylim([0,1])\n",
    "        if i == 0:\n",
    "            axs[i,j].set_title(rev_annots[int(avg.comment)], fontsize=fontsize)\n",
    "        if j == 0:\n",
    "            axs[i,j].set_ylabel(\"State \" + str(i+1), fontsize=fontsize)\n",
    "            \n",
    "        if i == K-1:\n",
    "            axs[i,j].set_xlabel(\"Time (s)\", fontsize=fontsize)\n",
    "            axs[i,j].tick_params(axis='x', which='major', labelsize=labelsize)\n",
    "            axs[i,j].tick_params(axis='x', which='minor', labelsize=labelsize-5)\n",
    "\n",
    "plt.savefig(\"/home/guibert/MEG_analysis/states_study.pdf\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8460da",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_raw.annotations.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't really see state occupancy overall. We should look at complete epochs for a better description.\n",
    "ev_ids_sorted = np.asarray(list(event_ids.values()))[sort_events_id(list(events_id.values()))]\n",
    "condition_names = [rev_annots[i] for i in ev_ids_sorted]\n",
    "event_type_epochs = [mne.Epochs(state_raw, events[:-1,:], event_id=i, picks=state_raw.ch_names) for i in ev_ids_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type_epochs[0].get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75bec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by looking at average tendencies, shall we?\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Let's create one epochs array per \n",
    "figs, axs = plt.subplots(nrows=K, ncols=len(event_type_epochs), figsize=(150,150))\n",
    "\n",
    "fontsize=90\n",
    "labelsize=50\n",
    "\n",
    "for i in range(K):\n",
    "    for j in range(len(avgs)):\n",
    "        epochs_j = event_type_epochs[j].get_data()\n",
    "        for l in range(epochs_j.shape[0]):\n",
    "            axs[i,j].plot(epochs.times, epochs_j[l,i,:]) #, title=rev_annots[int(avg.comment)])\n",
    "        axs[i,j].set_ylim([0,1])\n",
    "        if i == 0:\n",
    "            axs[i,j].set_title(condition_names[j], fontsize=fontsize)\n",
    "        if j == 0:\n",
    "            axs[i,j].set_ylabel(\"State \" + str(i+1), fontsize=fontsize)\n",
    "            \n",
    "        if i == K-1:\n",
    "            axs[i,j].set_xlabel(\"Time (s)\", fontsize=fontsize)\n",
    "            axs[i,j].tick_params(axis='x', which='major', labelsize=labelsize)\n",
    "            axs[i,j].tick_params(axis='x', which='minor', labelsize=labelsize-5)\n",
    "\n",
    "plt.savefig(\"/home/guibert/MEG_analysis/states_study.pdf\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a03fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(events_id.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0944e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans_mats_epoch_wise(X):\n",
    "    n_epochs, k, n_t = X.shape\n",
    "    trans_mats = np.zeros((n_epochs, k, k))\n",
    "    for e in range(n_epochs):\n",
    "        state_sequence = np.where(X[e])[0]\n",
    "        for i in range(1, n_t):\n",
    "            trans_mats[e, state_sequence[i-1], state_sequence[i]] += 1\n",
    "        for i in range(k):\n",
    "            s = np.sum(trans_mats[e, i,:])\n",
    "            if s > 0:\n",
    "                trans_mats[e, i,:] /= np.sum(trans_mats[e, i,:])\n",
    "    return trans_mats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_1back_tc.get_data()[0].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b66aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_raw.times[events[0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e172789",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf06869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_from(state_raw, events, event_id):\n",
    "    epochs_event = mne.Epochs(state_raw, events[:-1,:], event_id=event_id, picks=state_raw.ch_names, tmax=1.5)\n",
    "    # Let's get the 6th state:\n",
    "    return get_trans_mats_epoch_wise(epochs_event.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b445ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mats_2back_tc = get_event_from(state_raw, events, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mats_0back_tc = get_event_from(state_raw, events, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22499c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mats_0back_dc = get_event_from(state_raw, events, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30547560",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mats_0back_dc[0], vmin=0.8, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26123b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mats_2back_tc[0], vmin=0.8, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mats_0back_dc[3], vmin=0.8, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mats_0back_dc[1], vmin=0.8, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4186b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mats_0back_tc[0], vmin=0.8, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e32950",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mats_0back_tc[1], vmin=0.9, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c205d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_2back_tc = mne.Epochs(state_raw, events[:-1,:], event_id=6, picks=state_raw.ch_names)\n",
    "state6_2back_tc = epochs_2back_tc.get_data()[:,5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state6_1back_tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state6_2back_tc[7,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_1back_tc = mne.Epochs(state_raw, events[:-1,:], event_id=4, picks=state_raw.ch_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b56f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(epochs_1back_tc.get_data()[0][:,0])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_1back_tc.get_data()[0,:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad58d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(epochs_1back_tc.get_data()[0,:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9056e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_raw.annotations.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb5252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb18edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6683a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915d70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c2814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71299891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0e4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be6576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/1006/centers_10.csv\", kmeans.cluster_centers_, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921774a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/media/miplab-nas2/Data/guibert/nBack_complete/working_dir/nBack_Share_HC/MEGDATA/1006/covs_10.csv\", np.reshape(covs, (covs.shape[0]*covs.shape[1], covs.shape[2])), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "covs[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07bb1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "remodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120894ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa32045",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(remodel.transmat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linalg.svd(remodel.covars_[0])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa756c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_seq = remodel.predict(pca_data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a943eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = np.cov(stc.data[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.linalg.svd(cov_mat)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ec27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07999fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"filtered_events.tsv\", filt_events,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561d43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaeaa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linalg.svd(np.cov(pca_data))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e18cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we want to plot state occupancy as a function of time w.r.t stimuli\n",
    "for i in range(10):\n",
    "    plt.imshow(remodel.covars_[i], vmin=0, vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.average(by_event_type=2, picks= ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_raw.plot(events=filt_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676444c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9cbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_raw.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne._fiff.pick import _picks_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ffb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "_picks_to_idx(epochs.info, ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ce15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_epochs_image(epochs, picks=ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e7b5b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs.average(picks=ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702295a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs.get_data()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e953e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_raw.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fbd557",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f049949",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(state_assignments, return_counts=True)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
